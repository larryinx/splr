# SPLR Architecture Configuration

name: splr_hrm_gpt

# Model architecture
hidden_size: 768
max_position_embeddings: 320
num_attention_heads: 8
num_key_value_heads: 8
intermediate_size: 2048
tie_word_embeddings: false

# TRM recursive reasoning
hierarchical_reasoning: true
L_cycles: 2
H_cycles: 2
L_layers: 4
H_layers: 4
L_grad_cycles: 1
H_grad_cycles: 1

# Halting
halt_max_steps: 16
halt_exploration_prob: 0.1

# Multi-step reasoning
max_reasoning_steps: 6

# Task embeddings
task_emb_len: 1
task_emb_ndim: 768
num_task_identifiers: 1

# Inter-step reasoning
enable_inter_latent: true
inter_reasoning_only: false

# Embedding loading
load_embedding: openai-community/gpt2

# Attention
attention_bias: false
attention_dropout: 0.0

# Position encoding
rope_theta: 10000.0

# Normalization
rms_norm_eps: 1.0e-6

# Forward dtype
forward_dtype: bfloat16

# ACT options
no_ACT_continue: true
